name: Benchmark

on:
  pull_request:
    branches: [ main ]
    
permissions:
  contents: read
  pull-requests: write

jobs:
  benchmark:
    name: Performance Regression Check
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-benchmark psutil
          
      - name: Run benchmark
        run: |
          pytest benchmark/ --benchmark-only --benchmark-json output.json
        env:
          PYTHONPATH: ${{ github.workspace }}
          
      - name: Download previous benchmark data
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: benchmark
          path: ./cache
          
      - name: Store benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: Python Benchmark
          tool: 'pytest'
          output-file-path: output.json
          external-data-json-path: ./cache/benchmark-data.json
          fail-on-alert: true
          comment-on-alert: true
          alert-threshold: '200%'
          github-token: ${{ secrets.GITHUB_TOKEN }}
          alert-comment-cc-users: '@maintainers'
          
      - name: Generate benchmark report
        id: benchmark-report
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const benchmarkData = JSON.parse(fs.readFileSync('output.json', 'utf8'));
            
            let report = '## Benchmark Results\n\n';
            report += '| Test | Mean (ms) | StdDev | Iterations |\n';
            report += '|------|-----------|---------|------------|\n';
            
            for (const benchmark of benchmarkData.benchmarks) {
              const mean = (benchmark.stats.mean * 1000).toFixed(2);
              const stddev = (benchmark.stats.stddev * 1000).toFixed(2);
              report += `| ${benchmark.name} | ${mean} | ${stddev} | ${benchmark.stats.iterations} |\n`;
            }
            
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.payload.pull_request.number,
            });
            
            const benchmarkComment = comments.find(comment => 
              comment.body.startsWith('## Benchmark Results')
            );
            
            if (benchmarkComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: benchmarkComment.id,
                body: report,
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.payload.pull_request.number,
                body: report,
              });
            }

      - name: Store Benchmark Results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark
          path: ./cache/benchmark-data.json
          retention-days: 90
          
      - name: Performance Regression Check
        if: ${{ steps.benchmark-report.outputs.has_regression == 'true' }}
        run: exit 1
